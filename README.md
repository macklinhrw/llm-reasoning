## LLM reasoning

Currently Refactoring

### Results on GSM8K

`Qwen2.5-7B-Instruct` - GSM8K - 87% Accuracy (85.4 reported)
`Llama-3.2-3B-Instruct` - GSM8K - 69.45% Accuracy (77.7 reported 0-shot CoT)
`Llama-3.1-8B-Instruct` - GSM8K - 79.61% Accuracy (84.5 reported 8-shot CoT)
